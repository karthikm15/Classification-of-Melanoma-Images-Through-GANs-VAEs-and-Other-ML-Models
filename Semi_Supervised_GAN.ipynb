{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semi-Supervised GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNUMpXkpR793KD0ZX1MhwmS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikm15/Semi-Supervised-GANs-For-Melanoma-Detection/blob/main/Semi_Supervised_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8ToEwFKE99g"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import (Activation, BatchNormalization, Concatenate, Dense,\n",
        "                          Dropout, Flatten, Input, Lambda, Reshape)\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import boto3\n",
        "import shutil\n",
        "\n",
        "from numpy import vstack"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_Fnyo9fFIYR"
      },
      "source": [
        "img_rows = 100\n",
        "img_cols = 100\n",
        "channels = 1\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "\n",
        "z_dim = 100\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "list1 = os.listdir('./unlabeled_resize/')\n",
        "number_files_unlabeled = len(list1)\n",
        "num_of_unlabeled_imgs = number_files_unlabeled\n",
        "\n",
        "list2_m = os.listdir('./train_resize/melanoma/')\n",
        "number_files_train_m = len(list2_m)\n",
        "list2_nm = os.listdir('./train_resize/non-melanoma/')\n",
        "number_files_train_nm = len(list2_nm)\n",
        "number_files_train = number_files_train_m + number_files_train_nm\n",
        "num_of_train_imgs = number_files_train\n",
        "\n",
        "list3_m = os.listdir('./valid_resize/melanoma/')\n",
        "number_files_test_m = len(list3_m)\n",
        "list3_nm = os.listdir('./valid_resize/non-melanoma/')\n",
        "number_files_test_nm = len(list3_nm)\n",
        "number_files_test = number_files_test_m + number_files_test_nm\n",
        "num_of_test_imgs = number_files_test"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvuVB_d-FJup"
      },
      "source": [
        "def prepare(filepath, IMG_SIZE):\n",
        "    img_array = cv2.imread(filepath) \n",
        "    try:\n",
        "      res = cv2.resize(img_array, dsize=(IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
        "    except:\n",
        "      print(filepath)\n",
        "    res = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
        "    return res\n",
        "\n",
        "\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self):\n",
        "        folders = ['melanoma', 'non-melanoma']\n",
        "        \n",
        "        self.x_train = []\n",
        "        self.y_train = []\n",
        "        self.x_test = []\n",
        "        self.y_test = []\n",
        "        self.x_unlabeled = []\n",
        "        for folder in folders:\n",
        "            for filename in os.listdir(\"./train_resize/\" + folder):\n",
        "                if (filename != '.ipynb_checkpoints'):\n",
        "                  image_data = prepare((\"./train_resize/\" + folder + \"/\" + filename), 100)\n",
        "                  index = folders.index(folder)\n",
        "                  \n",
        "                  self.x_train.append(image_data)\n",
        "                  self.y_train.append(index)\n",
        "        \n",
        "        for folder in folders:\n",
        "            for filename in os.listdir(\"./valid_resize/\" + folder):\n",
        "                if (filename != '.ipynb_checkpoints'):\n",
        "                  image_data = prepare((\"./valid_resize/\" + folder + \"/\" + filename), 100)\n",
        "                  index = folders.index(folder)\n",
        "                  \n",
        "                  self.x_test.append(image_data)\n",
        "                  self.y_test.append(index)\n",
        "        \n",
        "        self.x_train = np.array(self.x_train)\n",
        "        self.y_train = np.array(self.y_train)\n",
        "        self.x_test = np.array(self.x_test)\n",
        "        self.y_test = np.array(self.y_test)\n",
        "        \n",
        "        for filename in os.listdir(\"./unlabeled_resize/\"):\n",
        "            if (filename != '.ipynb_checkpoints'):\n",
        "              image_data = prepare((\"./unlabeled_resize/\" + filename), 100)\n",
        "\n",
        "              self.x_unlabeled.append(image_data)\n",
        "        \n",
        "        self.x_unlabeled = np.array(self.x_unlabeled)\n",
        "            \n",
        "        def preprocess_imgs(x, process_img):\n",
        "            x = (x.astype(np.float32) - 127.5) / 127.5\n",
        "            if (process_img):\n",
        "                x = x.reshape(3, -1, 100, 100, 1)[0]\n",
        "            return x\n",
        "\n",
        "        def preprocess_labels(y):\n",
        "            return y.reshape(-1, 1)\n",
        "\n",
        "        self.x_train = preprocess_imgs(self.x_train, True)\n",
        "        self.y_train = preprocess_labels(self.y_train)\n",
        "\n",
        "        self.x_test = preprocess_imgs(self.x_test, True)\n",
        "        self.y_test = preprocess_labels(self.y_test)\n",
        "        \n",
        "        self.x_unlabeled = preprocess_imgs(self.x_unlabeled, True)\n",
        "\n",
        "    def batch_labeled(self, batch_size):\n",
        "        idx = np.random.randint(0, num_of_train_imgs, batch_size)\n",
        "        imgs = self.x_train[idx]\n",
        "        labels = self.y_train[idx]\n",
        "        return imgs, labels\n",
        "\n",
        "    def batch_unlabeled(self, batch_size):\n",
        "        idx = np.random.randint(0, num_of_unlabeled_imgs, batch_size)\n",
        "        imgs = self.x_unlabeled[idx]\n",
        "        return imgs\n",
        "\n",
        "    def training_set(self):\n",
        "        return self.x_train, self.y_train\n",
        "\n",
        "    def test_set(self):\n",
        "        return self.x_test, self.y_test\n",
        "\n",
        "dataset = Dataset()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_qS_qo9FNpS"
      },
      "source": [
        "\n",
        "def build_generator(z_dim):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256 * 25 * 25, input_dim=z_dim))\n",
        "    model.add(Reshape((25, 25, 256)))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n",
        "\n",
        "    model.add(Activation('tanh'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTtRI9NPFPbW"
      },
      "source": [
        "def build_discriminator_net(img_shape):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(\n",
        "        Conv2D(batch_size*2,\n",
        "               kernel_size=(3),\n",
        "               strides=2,\n",
        "               input_shape=(100,100,1),\n",
        "               padding='same'))\n",
        "\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    model.add(\n",
        "        Conv2D(batch_size*4,\n",
        "               kernel_size=(3),\n",
        "               strides=2,\n",
        "               input_shape=(100,100,1),\n",
        "               padding='same'))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    model.add(\n",
        "        Conv2D(batch_size*8,\n",
        "               kernel_size=(3),\n",
        "               strides=2,\n",
        "               input_shape=(100,100,1),\n",
        "               padding='same'))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(num_classes))\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l70YlyDTFWME"
      },
      "source": [
        "def build_discriminator_supervised(discriminator_net):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(discriminator_net)\n",
        "\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXTk_qnTFYUH"
      },
      "source": [
        "def build_discriminator_unsupervised(discriminator_net):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(discriminator_net)\n",
        "\n",
        "    def predict(x):\n",
        "        prediction = 1.0 - (1.0 /\n",
        "                            (K.sum(K.exp(x), axis=-1, keepdims=True) + 1.0))\n",
        "\n",
        "        return prediction\n",
        "\n",
        "    model.add(Lambda(predict))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SlFR0c9FZoO"
      },
      "source": [
        "def build_gan(generator, discriminator):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(generator)\n",
        "    model.add(discriminator)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_aYBHUXFcq0"
      },
      "source": [
        "discriminator_net = build_discriminator_net(img_shape)\n",
        "\n",
        "discriminator_supervised = build_discriminator_supervised(discriminator_net)\n",
        "discriminator_supervised.compile(loss='categorical_crossentropy',\n",
        "                                 metrics=['accuracy'],\n",
        "                                 optimizer=Adam())\n",
        "\n",
        "discriminator_unsupervised = build_discriminator_unsupervised(\n",
        "                                 discriminator_net)\n",
        "discriminator_unsupervised.compile(loss='binary_crossentropy',\n",
        "                                   optimizer=Adam())\n",
        "generator = build_generator(z_dim)\n",
        "discriminator_unsupervised.trainable = False\n",
        "gan = build_gan(generator, discriminator_unsupervised)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate = 0.0001))\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-K6JyYVFfhU"
      },
      "source": [
        "supervised_losses = []\n",
        "iteration_checkpoints = []\n",
        "def train(iterations, batch_size, sample_interval):\n",
        "\n",
        "    real = np.ones((batch_size, 1))\n",
        "\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "\n",
        "        imgs, labels = dataset.batch_labeled(batch_size*2)\n",
        "        labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "        imgs_unlabeled = dataset.batch_unlabeled(batch_size)\n",
        "\n",
        "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "        gen_imgs = generator.predict(z)\n",
        "        \n",
        "        images, label = vstack((imgs_unlabeled, gen_imgs)), vstack((real, fake))\n",
        "\n",
        "        d_loss_supervised, accuracy = discriminator_supervised.train_on_batch(imgs, labels)\n",
        " \n",
        "        predictions = discriminator_unsupervised.predict(generator.predict(z))\n",
        "\n",
        "        squared_diff_image = tf.square(1-predictions)\n",
        "        ssd_images = tf.reduce_sum(squared_diff_image, [1])\n",
        "        error_images = tf.reduce_mean(ssd_images)\n",
        "\n",
        "        d_loss_unsupervised = error_images.numpy()\n",
        "        if (d_loss_unsupervised > 0.05):\n",
        "            d_loss_real = discriminator_unsupervised.train_on_batch(imgs_unlabeled, real)\n",
        "\n",
        "            d_loss_fake = discriminator_unsupervised.train_on_batch(gen_imgs, fake)\n",
        "\n",
        "            d_loss_unsupervised = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "\n",
        "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "        gen_imgs = generator.predict(z)\n",
        "\n",
        "        g_loss = gan.train_on_batch(z, np.ones((batch_size, 1)))\n",
        "\n",
        "        if (iteration + 1) % sample_interval == 0:\n",
        "\n",
        "            supervised_losses.append(d_loss_supervised)\n",
        "            iteration_checkpoints.append(iteration + 1)\n",
        "            \n",
        "            print(\n",
        "                \"%d [D loss supervised: %.4f, acc.: %.2f%%] [D loss unsupervised: %.4f] [G loss: %f]\" %(iteration + 1, d_loss_supervised, 100 * accuracy,\n",
        "                  d_loss_unsupervised, g_loss))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWnLqBKpFFEv",
        "outputId": "6bfbd246-ae7d-4791-ac0d-9d755d1e254b"
      },
      "source": [
        "iterations = 500\n",
        "sample_interval = 10\n",
        "\n",
        "train(iterations, batch_size, sample_interval)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 [D loss supervised: 2.8548, acc.: 34.38%] [D loss unsupervised: 0.1192] [G loss: 0.368392]\n",
            "20 [D loss supervised: 1.2988, acc.: 53.12%] [D loss unsupervised: 0.0004] [G loss: 0.265805]\n",
            "30 [D loss supervised: 1.1331, acc.: 59.38%] [D loss unsupervised: 0.0006] [G loss: 0.145179]\n",
            "40 [D loss supervised: 1.7777, acc.: 56.25%] [D loss unsupervised: 0.0467] [G loss: 0.066678]\n",
            "50 [D loss supervised: 1.5874, acc.: 53.12%] [D loss unsupervised: 0.0441] [G loss: 0.012702]\n",
            "60 [D loss supervised: 1.3373, acc.: 62.50%] [D loss unsupervised: 0.0394] [G loss: 0.006635]\n",
            "70 [D loss supervised: 1.9358, acc.: 53.12%] [D loss unsupervised: 0.0331] [G loss: 0.002638]\n",
            "80 [D loss supervised: 0.8893, acc.: 43.75%] [D loss unsupervised: 0.0330] [G loss: 0.000664]\n",
            "90 [D loss supervised: 1.5420, acc.: 59.38%] [D loss unsupervised: 0.0303] [G loss: 0.000462]\n",
            "100 [D loss supervised: 1.0569, acc.: 68.75%] [D loss unsupervised: 0.0279] [G loss: 0.000103]\n",
            "110 [D loss supervised: 1.4567, acc.: 43.75%] [D loss unsupervised: 0.0251] [G loss: 0.000305]\n",
            "120 [D loss supervised: 0.8745, acc.: 68.75%] [D loss unsupervised: 0.0250] [G loss: 0.001324]\n",
            "130 [D loss supervised: 1.2046, acc.: 68.75%] [D loss unsupervised: 0.0221] [G loss: 0.000937]\n",
            "140 [D loss supervised: 3.1070, acc.: 53.12%] [D loss unsupervised: 0.0237] [G loss: 0.000098]\n",
            "150 [D loss supervised: 1.5514, acc.: 53.12%] [D loss unsupervised: 0.0218] [G loss: 0.000028]\n",
            "160 [D loss supervised: 0.7923, acc.: 62.50%] [D loss unsupervised: 0.0197] [G loss: 0.000210]\n",
            "170 [D loss supervised: 0.8126, acc.: 65.62%] [D loss unsupervised: 0.0179] [G loss: 0.000111]\n",
            "180 [D loss supervised: 0.9679, acc.: 68.75%] [D loss unsupervised: 0.0154] [G loss: 0.000173]\n",
            "190 [D loss supervised: 0.9855, acc.: 56.25%] [D loss unsupervised: 0.0139] [G loss: 0.000074]\n",
            "200 [D loss supervised: 1.5036, acc.: 59.38%] [D loss unsupervised: 0.0133] [G loss: 0.000044]\n",
            "210 [D loss supervised: 1.7434, acc.: 46.88%] [D loss unsupervised: 0.0118] [G loss: 0.000244]\n",
            "220 [D loss supervised: 0.4111, acc.: 75.00%] [D loss unsupervised: 0.0118] [G loss: 0.000051]\n",
            "230 [D loss supervised: 0.9217, acc.: 62.50%] [D loss unsupervised: 0.0114] [G loss: 0.000095]\n",
            "240 [D loss supervised: 1.3592, acc.: 59.38%] [D loss unsupervised: 0.0121] [G loss: 0.000058]\n",
            "250 [D loss supervised: 2.1308, acc.: 59.38%] [D loss unsupervised: 0.0104] [G loss: 0.000036]\n",
            "260 [D loss supervised: 0.5871, acc.: 81.25%] [D loss unsupervised: 0.0106] [G loss: 0.000389]\n",
            "270 [D loss supervised: 0.3889, acc.: 78.12%] [D loss unsupervised: 0.0094] [G loss: 0.000691]\n",
            "280 [D loss supervised: 1.3435, acc.: 46.88%] [D loss unsupervised: 0.0102] [G loss: 0.000760]\n",
            "290 [D loss supervised: 0.6327, acc.: 68.75%] [D loss unsupervised: 0.0077] [G loss: 0.000014]\n",
            "300 [D loss supervised: 1.3681, acc.: 59.38%] [D loss unsupervised: 0.0093] [G loss: 0.000041]\n",
            "310 [D loss supervised: 0.8208, acc.: 37.50%] [D loss unsupervised: 0.0110] [G loss: 0.000176]\n",
            "320 [D loss supervised: 1.0986, acc.: 56.25%] [D loss unsupervised: 0.0113] [G loss: 0.000243]\n",
            "330 [D loss supervised: 0.6666, acc.: 62.50%] [D loss unsupervised: 0.0124] [G loss: 0.000009]\n",
            "340 [D loss supervised: 0.7908, acc.: 59.38%] [D loss unsupervised: 0.0112] [G loss: 0.000001]\n",
            "350 [D loss supervised: 0.9169, acc.: 65.62%] [D loss unsupervised: 0.0099] [G loss: 0.000000]\n",
            "360 [D loss supervised: 1.7965, acc.: 50.00%] [D loss unsupervised: 0.0126] [G loss: 0.000003]\n",
            "370 [D loss supervised: 0.9543, acc.: 62.50%] [D loss unsupervised: 0.0120] [G loss: 0.000003]\n",
            "380 [D loss supervised: 1.0878, acc.: 46.88%] [D loss unsupervised: 0.0107] [G loss: 0.000027]\n",
            "390 [D loss supervised: 0.6078, acc.: 65.62%] [D loss unsupervised: 0.0093] [G loss: 0.000004]\n",
            "400 [D loss supervised: 0.8343, acc.: 53.12%] [D loss unsupervised: 0.0097] [G loss: 0.000111]\n",
            "410 [D loss supervised: 0.7433, acc.: 68.75%] [D loss unsupervised: 0.0094] [G loss: 0.000001]\n",
            "420 [D loss supervised: 0.7652, acc.: 62.50%] [D loss unsupervised: 0.0069] [G loss: 0.000003]\n",
            "430 [D loss supervised: 0.8019, acc.: 53.12%] [D loss unsupervised: 0.0066] [G loss: 0.000000]\n",
            "440 [D loss supervised: 1.4844, acc.: 56.25%] [D loss unsupervised: 0.0100] [G loss: 0.000033]\n",
            "450 [D loss supervised: 0.6299, acc.: 71.88%] [D loss unsupervised: 0.0079] [G loss: 0.000015]\n",
            "460 [D loss supervised: 0.7188, acc.: 68.75%] [D loss unsupervised: 0.0029] [G loss: 0.000001]\n",
            "470 [D loss supervised: 0.5678, acc.: 78.12%] [D loss unsupervised: 0.0007] [G loss: 0.000000]\n",
            "480 [D loss supervised: 0.7265, acc.: 65.62%] [D loss unsupervised: 0.0004] [G loss: 0.000001]\n",
            "490 [D loss supervised: 0.7042, acc.: 59.38%] [D loss unsupervised: 0.0008] [G loss: 0.000001]\n",
            "500 [D loss supervised: 1.0270, acc.: 50.00%] [D loss unsupervised: 0.0003] [G loss: 0.000002]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgy17Ie1FbvX",
        "outputId": "be48d385-7e84-452f-c817-9911e8930294"
      },
      "source": [
        "x, y = dataset.test_set()\n",
        "y = to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "_, accuracy = discriminator_supervised.evaluate(x, y)\n",
        "# print(\"Test Accuracy: %.2f%%\" % (100 * accuracy))\n",
        "\n",
        "\n",
        "def prepare(filepath, IMG_SIZE):\n",
        "    img_array = cv2.imread(filepath) \n",
        "    res = cv2.resize(img_array, dsize=(IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
        "    return res\n",
        "\n",
        "img_array = cv2.imread('./train_resize/melanoma/0101_1.jpg')\n",
        "res = cv2.resize(img_array, dsize=(100, 100), interpolation=cv2.INTER_CUBIC)\n",
        "res = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
        "res=res.reshape(3,100,100)\n",
        "x, y = dataset.training_set()\n",
        "\n",
        "z_one = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "gen_images = generator.predict(z_one)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 0s 5ms/step - loss: 0.9182 - accuracy: 0.4875\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}